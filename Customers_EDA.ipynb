{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKxTsjd3rGTWf7aeuaAaDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevejj4/Insurance-data-lifecycle/blob/main/Customers_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kql0lJRMBEFZ",
        "outputId": "93c9710e-f271-4ddd-ffdf-ebba51593e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (2.19.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.1)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.24.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.7.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.0)\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.2)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880745 sha256=64d6e11063f1fb54ba14f133d5629404ee75aec63500ad78fd1ffdb3c8ee6454\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-bigquery\n",
        "!pip install pyspark==3.1.2\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticating and initializing BigQuery client\n",
        "project_id = 'river-messenger-430112-e1'\n",
        "client = bigquery.Client(project=project_id)"
      ],
      "metadata": {
        "id": "jHLN9jQIBLtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying to get interactions table\n",
        "query_customers = \"\"\"\n",
        "SELECT * FROM `river-messenger-430112-e1.Insurance_data.customers`;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9PXxVLOsBcbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the query and converting to a pandas DataFrame\n",
        "df_customers = client.query(query_customers).to_dataframe()"
      ],
      "metadata": {
        "id": "_LrCkhWABlPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('BigQuerySparkApp') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Converting pandas DataFrame to Spark DataFrame\n",
        "# Using iterrows() instead of iteritems() to iterate over DataFrame rows\n",
        "spark_df_customers = spark.createDataFrame(df_customers.to_dict('records'))\n",
        "\n",
        "# Show the schema and first few rows\n",
        "spark_df_customers.printSchema()\n",
        "#spark_df_interactions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--SH5eECKBX",
        "outputId": "560e4370-a0e0-4984-f34c-617f5f37acf5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Age: long (nullable = true)\n",
            " |-- CustomerID: long (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df_customers.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-8TQwbZDDMu",
        "outputId": "b0326dd3-f685-4941-85ca-af07b74d0448"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------+-----------------+\n",
            "|Age|CustomerID|Gender|           Region|\n",
            "+---+----------+------+-----------------+\n",
            "| 18|        43|  Male|   Allisonborough|\n",
            "| 18|       189|  Male|      Lake Lauren|\n",
            "| 18|       373|  Male|      North Renee|\n",
            "| 18|       411|  Male|West Lindsayville|\n",
            "| 18|       420|  Male|    Chandlershire|\n",
            "+---+----------+------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when, count, sum\n",
        "\n",
        "# Calculate age distribution with percentages\n",
        "age_distribution = spark_df_customers.select(\n",
        "    when(col(\"age\") < 25, \"Under 25\")\n",
        "    .when((col(\"age\") >= 25) & (col(\"age\") <= 34), \"25-34\")\n",
        "    .when((col(\"age\") >= 35) & (col(\"age\") <= 44), \"35-44\")\n",
        "    .when((col(\"age\") >= 45) & (col(\"age\") <= 54), \"45-54\")\n",
        "    .when((col(\"age\") >= 55) & (col(\"age\") <= 64), \"55-64\")\n",
        "    .otherwise(\"65+\")\n",
        "    .alias(\"age_group\")\n",
        ").groupBy(\"age_group\").agg(count(\"*\").alias(\"count\"))\n",
        "\n",
        "# Calculate total count\n",
        "total_count = spark_df_customers.count()\n",
        "\n",
        "# Add percentage column\n",
        "age_distribution_with_percentage = age_distribution.withColumn(\n",
        "    \"percentage\", (col(\"count\") / total_count) * 100\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "age_distribution_with_percentage.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4_W5zYtFfCZ",
        "outputId": "b08306af-f18c-425d-84e9-6c2bd05c5ad1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+------------------+\n",
            "|age_group|count|        percentage|\n",
            "+---------+-----+------------------+\n",
            "|    45-54|  379|18.912175648702593|\n",
            "|    55-64|  394|19.660678642714572|\n",
            "| Under 25|  277|13.822355289421157|\n",
            "|    35-44|  378|18.862275449101794|\n",
            "|    25-34|  355|17.714570858283434|\n",
            "|      65+|  221|11.027944111776447|\n",
            "+---------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count\n",
        "\n",
        "# Assuming 'gender' is the column containing gender information\n",
        "gender_distribution = spark_df_customers.groupBy(\"gender\").agg(count(\"*\").alias(\"count\"))\n",
        "\n",
        "# Calculate total count\n",
        "total_count = spark_df_customers.count()\n",
        "\n",
        "# Add percentage column\n",
        "gender_distribution_with_percentage = gender_distribution.withColumn(\n",
        "    \"percentage\", (col(\"count\") / total_count) * 100\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "gender_distribution_with_percentage.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qCl5fEDGU5E",
        "outputId": "b0358c85-bb3e-48e5-9192-d0f70b02714e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+------------------+\n",
            "|gender|count|        percentage|\n",
            "+------+-----+------------------+\n",
            "|Female|  962|48.003992015968066|\n",
            "|  Male| 1042|51.996007984031934|\n",
            "+------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}